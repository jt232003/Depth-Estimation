{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-30T05:14:04.810334Z","iopub.execute_input":"2025-03-30T05:14:04.810646Z","iopub.status.idle":"2025-03-30T05:14:05.112162Z","shell.execute_reply.started":"2025-03-30T05:14:04.810618Z","shell.execute_reply":"2025-03-30T05:14:05.111286Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T05:14:05.113388Z","iopub.execute_input":"2025-03-30T05:14:05.113817Z","iopub.status.idle":"2025-03-30T05:14:05.538995Z","shell.execute_reply.started":"2025-03-30T05:14:05.113786Z","shell.execute_reply":"2025-03-30T05:14:05.538375Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"\ndef load_images(image_folder, depth_folder, num_samples=5):\n    image_files = sorted(os.listdir(image_folder))[:num_samples]\n    depth_files = sorted(os.listdir(depth_folder))[:num_samples]\n    \n    images, depths = [], []\n    \n    for img_file, depth_file in zip(image_files, depth_files):\n        img_path = os.path.join(image_folder, img_file)\n        depth_path = os.path.join(depth_folder, depth_file)\n        \n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        depth = cv2.imread(depth_path, cv2.IMREAD_UNCHANGED)\n        \n        images.append(image)\n        depths.append(depth)\n    \n    return images, depths\n\ndef visualize_samples(images, depths, num_samples=5):\n    plt.figure(figsize=(10, num_samples * 3))\n    \n    for i in range(num_samples):\n        plt.subplot(num_samples, 2, 2*i + 1)\n        plt.imshow(images[i])\n        plt.title(\"RGB Image\")\n        plt.axis(\"off\")\n        \n        plt.subplot(num_samples, 2, 2*i + 2)\n        plt.imshow(depths[i], cmap=\"plasma\")\n        plt.title(\"Depth Map\")\n        plt.axis(\"off\")\n    \n    plt.tight_layout()\n    plt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T05:14:05.540635Z","iopub.execute_input":"2025-03-30T05:14:05.540847Z","iopub.status.idle":"2025-03-30T05:14:05.547164Z","shell.execute_reply.started":"2025-03-30T05:14:05.540829Z","shell.execute_reply":"2025-03-30T05:14:05.546329Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Set dataset paths\ntrain_images = \"/kaggle/input/depth-estimation/competition-data/competition-data/training/images\"\ntrain_depth = \"/kaggle/input/depth-estimation/competition-data/competition-data/training/depths\"\n\n# Load and visualize\nimages, depths = load_images(train_images, train_depth)\nvisualize_samples(images, depths)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T05:14:05.548518Z","iopub.execute_input":"2025-03-30T05:14:05.548764Z","iopub.status.idle":"2025-03-30T05:14:05.659362Z","shell.execute_reply.started":"2025-03-30T05:14:05.548744Z","shell.execute_reply":"2025-03-30T05:14:05.658333Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-7317372b6eeb>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load and visualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mvisualize_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-75668b915cf8>\u001b[0m in \u001b[0;36mload_images\u001b[0;34m(image_folder, depth_folder, num_samples)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimage_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdepth_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/depth-estimation/competition-data/competition-data/training/images'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/depth-estimation/competition-data/competition-data/training/images'","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"import os\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef load_images(image_folder, depth_folder, num_samples=5, img_size=(224, 224)):\n    image_files = sorted(os.listdir(image_folder))[:num_samples]\n    depth_files = sorted(os.listdir(depth_folder))[:num_samples]\n    \n    images, depths = [], []\n    \n    for img_file, depth_file in zip(image_files, depth_files):\n        img_path = os.path.join(image_folder, img_file)\n        depth_path = os.path.join(depth_folder, depth_file)\n        \n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, img_size) / 255.0  # Normalize to [0,1]\n        \n        depth = cv2.imread(depth_path, cv2.IMREAD_UNCHANGED)\n        depth = cv2.resize(depth, img_size)\n        depth = MinMaxScaler().fit_transform(depth)  # Normalize depth to [0,1]\n        \n        images.append(image)\n        depths.append(depth)\n    \n    return np.array(images), np.array(depths)\n\ndef visualize_samples(images, depths, num_samples=5):\n    plt.figure(figsize=(10, num_samples * 3))\n    \n    for i in range(num_samples):\n        plt.subplot(num_samples, 2, 2*i + 1)\n        plt.imshow(images[i])\n        plt.title(\"RGB Image\")\n        plt.axis(\"off\")\n        \n        plt.subplot(num_samples, 2, 2*i + 2)\n        plt.imshow(depths[i], cmap=\"plasma\")\n        plt.title(\"Depth Map\")\n        plt.axis(\"off\")\n    \n    plt.tight_layout()\n    plt.show()\n\n# Set dataset paths\ntrain_images = \"/kaggle/input/depth-estimation/competition-data/competition-data/training/images\"\ntrain_depth = \"/kaggle/input/depth-estimation/competition-data/competition-data/training/depths\"\n\n# Load and visualize\nimages, depths = load_images(train_images, train_depth)\nvisualize_samples(images, depths)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T05:14:05.659779Z","iopub.status.idle":"2025-03-30T05:14:05.660025Z","shell.execute_reply":"2025-03-30T05:14:05.659927Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom sklearn.preprocessing import MinMaxScaler\nfrom torchvision.models import vit_b_16, ViT_B_16_Weights\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import roc_auc_score, accuracy_score, mean_squared_error\nfrom tqdm import tqdm\n\n# Dataset class\nclass DepthDataset(Dataset):\n    def __init__(self, image_folder, depth_folder, img_size=(224, 224)):\n        self.image_files = sorted(os.listdir(image_folder))\n        self.depth_files = sorted(os.listdir(depth_folder))\n        self.image_folder = image_folder\n        self.depth_folder = depth_folder\n        self.img_size = img_size\n        self.transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Resize(self.img_size),\n        ])\n    \n    def __len__(self):\n        return len(self.image_files)\n    \n    def __getitem__(self, idx):\n        img_path = os.path.join(self.image_folder, self.image_files[idx])\n        depth_path = os.path.join(self.depth_folder, self.depth_files[idx])\n        \n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, self.img_size) / 255.0\n        depth = cv2.imread(depth_path, cv2.IMREAD_UNCHANGED)\n        depth = cv2.resize(depth, self.img_size)\n        depth = MinMaxScaler().fit_transform(depth)\n        \n        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)\n        depth = torch.tensor(depth, dtype=torch.float32).unsqueeze(0)\n        \n        return image, depth\n\nclass DepthEstimationModel(nn.Module):\n    def __init__(self):\n        super(DepthEstimationModel, self).__init__()\n        \n        # Load pre-trained ResNet-50 model\n        resnet = models.resnet50(pretrained=True)\n        \n        # Modify the first convolution layer to accept 1-channel grayscale images\n        self.resnet = resnet\n        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        \n        # Remove the fully connected layer and add custom depth estimation head\n        self.resnet.fc = nn.Sequential(\n            nn.Linear(resnet.fc.in_features, 512),\n            nn.ReLU(),\n            nn.Linear(512, 1)  # Single output for depth estimation\n        )\n    \n    def forward(self, x):\n        return self.resnet(x)\n\n# Training function\ndef train_model(model, train_loader, val_loader, epochs=35, lr=1e-4):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    \n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n        all_preds, all_targets = [], []\n        \n        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n        for images, depths in loop:\n            images, depths = images.to(device), depths.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, depths)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            \n            all_preds.append(outputs.detach().cpu().numpy().flatten())\n            all_targets.append(depths.detach().cpu().numpy().flatten())\n            \n            loop.set_postfix(loss=total_loss / len(train_loader))\n        \n        # Validation phase\n        model.eval()\n        val_loss, val_preds, val_targets = 0, [], []\n        with torch.no_grad():\n            for images, depths in val_loader:\n                images, depths = images.to(device), depths.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, depths)\n                val_loss += loss.item()\n                val_preds.append(outputs.detach().cpu().numpy().flatten())\n                val_targets.append(depths.detach().cpu().numpy().flatten())\n        \n        mse = mean_squared_error(np.concatenate(val_targets), np.concatenate(val_preds))\n        #auc = roc_auc_score(np.concatenate(val_targets), np.concatenate(val_preds))\n        accuracy = accuracy_score(np.round(np.concatenate(val_targets)), np.round(np.concatenate(val_preds)))\n        mse = mean_squared_error(np.concatenate(val_targets), np.concatenate(val_preds))\n        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}, MSE: {mse:.4f}\")\n\n        #print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}, MSE: {mse:.4f}, AUC: {auc:.4f}, Accuracy: {accuracy:.4f}\")\n    \n    return model\n\n# Set dataset paths\ntrain_images = \"/kaggle/input/depth-estimation/competition-data/competition-data/training/images\"\ntrain_depth = \"/kaggle/input/depth-estimation/competition-data/competition-data/training/depths\"\nval_images = \"/kaggle/input/depth-estimation/competition-data/competition-data/validation/images\"\nval_depth = \"/kaggle/input/depth-estimation/competition-data/competition-data/validation/depths\"\n\n# Load dataset and create DataLoader\ndataset_train = DepthDataset(train_images, train_depth)\ndataset_val = DepthDataset(val_images, val_depth)\ntrain_loader = DataLoader(dataset_train, batch_size=16, shuffle=True)\nval_loader = DataLoader(dataset_val, batch_size=16, shuffle=False)\n\n# Initialize and train model\nmodel = DepthEstimationModel()\ntrained_model = train_model(model, train_loader, val_loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T05:14:05.660635Z","iopub.status.idle":"2025-03-30T05:14:05.660998Z","shell.execute_reply":"2025-03-30T05:14:05.660837Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\n\n# Test Dataset Class\nclass TestDepthDataset(Dataset):\n    def __init__(self, image_folder, img_size=(224, 224)):\n        self.image_files = sorted(os.listdir(image_folder))\n        self.image_folder = image_folder\n        self.img_size = img_size\n    \n    def __len__(self):\n        return len(self.image_files)\n    \n    def __getitem__(self, idx):\n        img_path = os.path.join(self.image_folder, self.image_files[idx])\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, self.img_size) / 255.0\n        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)\n        return image, self.image_files[idx]  # Return filename for saving\n\n# Function to generate predictions\ndef predict_and_save(model, test_loader, output_folder):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model.eval()\n\n    os.makedirs(output_folder, exist_ok=True)\n\n    with torch.no_grad():\n        for images, filenames in tqdm(test_loader, desc=\"Generating Predictions\"):\n            images = images.to(device)\n            outputs = model(images).cpu().numpy()\n\n            for i in range(len(outputs)):\n                depth_map = outputs[i][0]  # Extract depth map\n                depth_map = (depth_map - np.min(depth_map)) / (np.max(depth_map) - np.min(depth_map) + 1e-6)  # Normalize\n                depth_map = np.uint8(depth_map * 255)  # Convert to 8-bit grayscale\n\n                image_filename = os.path.join(output_folder, filenames[i])\n                cv2.imwrite(image_filename, depth_map)\n\n# Set test dataset paths\ntest_images = \"/kaggle/input/depth-estimation/competition-data/competition-data/testing/images\"\noutput_folder = \"/kaggle/working/test_predictions\"\n\n# Load test dataset\ntest_dataset = TestDepthDataset(test_images)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n\n# Generate test predictions\npredict_and_save(trained_model, test_loader, output_folder)\n\n# Convert images to CSV\ndef images_to_csv_with_metadata(image_folder, output_csv):\n    data = []\n    for idx, filename in enumerate(sorted(os.listdir(image_folder))):\n        if filename.endswith(\".png\"):\n            filepath = os.path.join(image_folder, filename)\n            image = cv2.imread(filepath, cv2.IMREAD_UNCHANGED)\n            image = cv2.resize(image, (128, 128))\n            image = image / 255.\n            image = (image - np.min(image)) / (np.max(image) - np.min(image) + 1e-6)\n            image = np.uint8(image * 255.)\n            image_flat = image.flatten()\n            row = [idx, filename] + image_flat.tolist()\n            data.append(row)\n    \n    num_columns = len(data[0]) - 2 if data else 0\n    column_names = [\"id\", \"ImageID\"] + [indx for indx in range(num_columns)]\n    df = pd.DataFrame(data, columns=column_names)\n\n    os.makedirs(\"/kaggle/working/csv\", exist_ok=True)\n    output_path = \"/kaggle/working/csv/prediction_v2.csv\"\n    df.to_csv(output_path, index=False)\n    print(f\"CSV saved at: {output_path}\")\n\n# Generate prediction_v2.csv\nimages_to_csv_with_metadata(output_folder, \"/kaggle/working/csv/prediction_v2.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T05:14:05.661872Z","iopub.status.idle":"2025-03-30T05:14:05.662255Z","shell.execute_reply":"2025-03-30T05:14:05.662065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\n\nmodel_path = \"/kaggle/working/depth_model.pth\"\n\n# Save the trained model\ntorch.save(trained_model.state_dict(), model_path)\n\nprint(f\"Model saved at: {model_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T05:14:05.663041Z","iopub.status.idle":"2025-03-30T05:14:05.663391Z","shell.execute_reply":"2025-03-30T05:14:05.663250Z"}},"outputs":[],"execution_count":null}]}